{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Enhancement and Evaluations\n",
    "\n",
    "- implement basic speech enhancement techniques, evaluate and visualize the quality of the enhancement\n",
    "\n",
    "- implement four different filtering methods: **Spectral-subtraction**, **Wiener-filter**, **linear filter** and a **VAD based filter**.\n",
    "\n",
    "In all these filters, two things are used: \n",
    "\n",
    "1. a constant average magnitude noise model \n",
    "\n",
    "2. an ideal noise estimate which is the true noise you generate to create the noisy signal. \n",
    "\n",
    "The enhanced signals are evaluated by computing the signal-to-noise ratios-global SNR and segmental SNR. \n",
    "\n",
    "To visualize the results, the segmental SNRs of all enhanced signals are plotted.\n",
    "\n",
    "Besides this, the spectrograms of the clean, noisy and the three enhanced results are plotted and visually inspected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following functions are implemented\n",
    "\n",
    "1. `noiseEst`: Estimate the noise for the noisy signal based on ideal and average noise models.\n",
    "\n",
    "2. `spectralSub`: Enhance the noisy signal by spectral subtraction.\n",
    "\n",
    "3. `wiener`:  Enhance the noisy signal by Wiener filter.\n",
    "\n",
    "4. `linear`: Enhance the noisy signal by linear filter.\n",
    "\n",
    "5. `vadEnhance`: Enhance the noisy signal by VAD based filter.\n",
    "\n",
    "6. `snrGlb`: Compute the global SNR of the enhanced signals\n",
    "\n",
    "7. `snrSeg`: Compute the frame-wise segmental SNR of the enhanced signals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "- Generate a noisy signal (additive white Gaussian noise of power -35dB)\n",
    "\n",
    "- Estimate the noise for the noisy signal, based on \n",
    "\t1. ideal estimate \n",
    "\t\n",
    "\t2. avg noise model, by completing \"noiseEst\". \n",
    "\t\n",
    "    (Note that this function should return estimates of the same dimension as the input noise matrix.)\n",
    "\n",
    "- Enhance the noisy signal by implementing the filtering functions \n",
    "    1) Spectral subtraction: \"spectralSub\", \n",
    "\t\n",
    "\t2) Wiener filter: \"wiener\", \n",
    "\t\n",
    "\t3) Linear filter: \"linear\", \n",
    "    \n",
    "\t4) VAD based filter: \"vadEnhance\"\n",
    "\n",
    "- Compute the global SNR and the frame-wise segmental SNR of the enhanced signals by computing\n",
    " \t1. snrGlb \n",
    " \t\n",
    "\t2. snrSeg\n",
    " \n",
    "- Plot and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare the speech signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the audio file and sampling rate\n",
    "Fs_target = 16000\n",
    "Fs,data_clean = wav.read('hello.wav')\n",
    "data_clean = data_clean[:, 0]\n",
    "\n",
    "# Transform signal from int16 (-32768 to 32767) to float32 (-1,1)\n",
    "if type(data_clean[0]) == np.int16:\n",
    "    data_clean = np.divide(data_clean,32768,dtype=np.float32)\n",
    "\n",
    "# Make sure the sampling rate is 16kHz\n",
    "if not (Fs == Fs_target):\n",
    "    data_clean = sig.resample_poly(data_clean,Fs_target,Fs)\n",
    "    Fs = Fs_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data sequence into windows.\n",
    "frame_length_ms = 25 # in miliseconds\n",
    "hop_length_ms = 12.5 # in miliseconds\n",
    "\n",
    "frame_length = int(np.around((frame_length_ms/1000)*Fs))# 25ms in samples\n",
    "hop_size = int(np.around((hop_length_ms/1000)*Fs))# 12.5 ms (25/2 ms) in samples (50% overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_matrix_clean = windowing(data_clean, frame_length, hop_size, 'hamming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 311)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_matrix_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speechprocessing",
   "language": "python",
   "name": "speechprocessing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
